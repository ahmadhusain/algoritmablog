---
title: "GridSearchCV"
author: "Muhammad Ariqleesta Hidayat"
date: '2021-05-22'
github: https://github.com/ariqleesta/algoritmablog
slug: gridsearchcv
categories:
  - Python
tags: 
  - Machine Learning
  - GridSearchCV
  - Data Manipulation
  - Feature Extraction
description: ''
featured: ''
featuredalt: ''
featuredpath: ''
linktitle: ''
type: post
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="background" class="section level2">
<h2>Background</h2>
<p>Proses pengerjaan <em>machine learning</em> pada umumnya meliputi uji coba berbagai model terhadap dataset dengan memilih model dengan performa terbaik. Untuk mendapatkan hasil prediksi data yang akurat, diperlukan tidak hanya model <em>machine learning</em> yang tepat, tetapi juga <em>hyperparameter</em> (parameter yang mengatur proses pembelajaran mesin) yang tepat pula yang dikenal dengan istilah <em>hyperparameter tuning</em>. Menentukan kombinasi yang tepat antara model dan <em>hyperparameter</em> seringkali menjadi tantangan.</p>
<p><em>Grid Search Cross Validation</em> adalah <strong>metode pemilihan kombinasi model dan <em>hyperparameter</em></strong> dengan cara menguji coba satu persatu kombinasi dan melakukan validasi untuk setiap kombinasi. Tujuannya adalah menentukan kombinasi yang menghasilkan performa model terbaik yang dapat dipilih untuk dijadikan model untuk prediksi.</p>
<center>
<img src="img/gscv.png" style="width:60.0%" />
</center>
<p>Artikel ini akan membahas bagaimana cara mengoptimasi model <em>machine learning</em> dengan menggunakan metoda <em>Grid Search Cross Validation</em>. Dengan adanya <em>Grid Search Cross Validation</em>, proses pemilihan model dan <em>hyperparameter tuning</em> menjadi lebih mudah. <em>Grid Search Cross Validation</em> melakukan validasi untuk setiap kombinasi model dan <em>hyperparameter</em> secara otomatis sehingga dapat menghemat waktu proses pengerjaan.</p>
</div>
<div id="import-library" class="section level2">
<h2>Import Library</h2>
<p>Import <em>library</em> umum yang digunakan dalam pengolahan data.</p>
<pre class="python"><code>import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings(&#39;ignore&#39;)

import matplotlib.pyplot as plt
import seaborn as sns</code></pre>
</div>
<div id="data-understanding" class="section level2">
<h2>Data Understanding</h2>
<p>Data yang digunakan pada artikel ini adalah data <a href="https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho">Vehicle</a> yang diperoleh dari kaggle . Model <em>machine learning</em> pada kasus ini dirancang untuk memprediksi harga mobil bekas berdasarkan kondisi kendaraan saat dijual.</p>
<pre class="python"><code>df = pd.read_csv(&#39;data_input/Car_details_v3.csv&#39;)</code></pre>
<pre class="python"><code>df.head()</code></pre>
<pre><code>#&gt;                            name  year  ...                    torque  seats
#&gt; 0        Maruti Swift Dzire VDI  2014  ...            190Nm@ 2000rpm    5.0
#&gt; 1  Skoda Rapid 1.5 TDI Ambition  2014  ...       250Nm@ 1500-2500rpm    5.0
#&gt; 2      Honda City 2017-2020 EXi  2006  ...     12.7@ 2,700(kgm@ rpm)    5.0
#&gt; 3     Hyundai i20 Sportz Diesel  2010  ...  22.4 kgm at 1750-2750rpm    5.0
#&gt; 4        Maruti Swift VXI BSIII  2007  ...     11.5@ 4,500(kgm@ rpm)    5.0
#&gt; 
#&gt; [5 rows x 13 columns]</code></pre>
<pre class="python"><code>df.shape</code></pre>
<pre><code>#&gt; (8128, 13)</code></pre>
<p>Data ini terdiri dari 8128 baris dengan 13 kolom. Kolom <code>selling_price</code> akan menjadi <em>target value</em> (nilai yang akan diprediksi). Berikut adalah deskripsi dari data ini.</p>
<pre class="python"><code>df.describe(include = &#39;all&#39;)</code></pre>
<pre><code>#&gt;                           name         year  ...          torque        seats
#&gt; count                     8128  8128.000000  ...            7906  7907.000000
#&gt; unique                    2058          NaN  ...             441          NaN
#&gt; top     Maruti Swift Dzire VDI          NaN  ...  190Nm@ 2000rpm          NaN
#&gt; freq                       129          NaN  ...             530          NaN
#&gt; mean                       NaN  2013.804011  ...             NaN     5.416719
#&gt; std                        NaN     4.044249  ...             NaN     0.959588
#&gt; min                        NaN  1983.000000  ...             NaN     2.000000
#&gt; 25%                        NaN  2011.000000  ...             NaN     5.000000
#&gt; 50%                        NaN  2015.000000  ...             NaN     5.000000
#&gt; 75%                        NaN  2017.000000  ...             NaN     5.000000
#&gt; max                        NaN  2020.000000  ...             NaN    14.000000
#&gt; 
#&gt; [11 rows x 13 columns]</code></pre>
<p>Kemudian perlu dilakukan pengecekan struktur data (tipe data) dan <em>missing value</em> pada dataset ini. Pengamatan terkait <em>missing value</em> dapat dilakukan secara <em>visual</em> dengan bantuan <em>library</em> <code>missingno</code>.</p>
<pre class="python"><code>import missingno as msno
plt.figure()</code></pre>

<pre class="python"><code>msno.matrix(df, figsize = (15,10))</code></pre>
<pre><code>#&gt; &lt;AxesSubplot:&gt;</code></pre>
<pre class="python"><code>plt.show()</code></pre>
<p><img src="/blog/2021-05-22-gridsearchcv_files/figure-html/unnamed-chunk-1-1.png" width="1440" style="display: block; margin: auto;" /></p>
<p>Berikut adalah informasi tekstual mengenai data yang hilang dan tipe data dari masing-masing kolom pada dataset ini.</p>
<pre class="python"><code>df.info()</code></pre>
<pre><code>#&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
#&gt; RangeIndex: 8128 entries, 0 to 8127
#&gt; Data columns (total 13 columns):
#&gt;  #   Column         Non-Null Count  Dtype  
#&gt; ---  ------         --------------  -----  
#&gt;  0   name           8128 non-null   object 
#&gt;  1   year           8128 non-null   int64  
#&gt;  2   selling_price  8128 non-null   int64  
#&gt;  3   km_driven      8128 non-null   int64  
#&gt;  4   fuel           8128 non-null   object 
#&gt;  5   seller_type    8128 non-null   object 
#&gt;  6   transmission   8128 non-null   object 
#&gt;  7   owner          8128 non-null   object 
#&gt;  8   mileage        7907 non-null   object 
#&gt;  9   engine         7907 non-null   object 
#&gt;  10  max_power      7913 non-null   object 
#&gt;  11  torque         7906 non-null   object 
#&gt;  12  seats          7907 non-null   float64
#&gt; dtypes: float64(1), int64(3), object(9)
#&gt; memory usage: 825.6+ KB</code></pre>
</div>
<div id="data-preparation" class="section level2">
<h2>Data Preparation</h2>
<p>Drop baris yang memiliki data yang hilang.</p>
<pre class="python"><code>df.dropna(inplace = True)</code></pre>
<p>Pisahkan data numerik dan data kategorikal.</p>
<pre class="python"><code>numerics = [&#39;int16&#39;, &#39;int32&#39;, &#39;int64&#39;, &#39;float16&#39;, &#39;float32&#39;, &#39;float64&#39;]

# Data numerik
df_num = df.select_dtypes(include=numerics)

# Data kategorikal
df_cat = df.drop(columns = df_num.columns, axis = 1)</code></pre>
<pre class="python"><code>df_num.head()</code></pre>
<pre><code>#&gt;    year  selling_price  km_driven  seats
#&gt; 0  2014         450000     145500    5.0
#&gt; 1  2014         370000     120000    5.0
#&gt; 2  2006         158000     140000    5.0
#&gt; 3  2010         225000     127000    5.0
#&gt; 4  2007         130000     120000    5.0</code></pre>
<pre class="python"><code>df_cat.head()</code></pre>
<pre><code>#&gt;                            name    fuel  ...   max_power                    torque
#&gt; 0        Maruti Swift Dzire VDI  Diesel  ...      74 bhp            190Nm@ 2000rpm
#&gt; 1  Skoda Rapid 1.5 TDI Ambition  Diesel  ...  103.52 bhp       250Nm@ 1500-2500rpm
#&gt; 2      Honda City 2017-2020 EXi  Petrol  ...      78 bhp     12.7@ 2,700(kgm@ rpm)
#&gt; 3     Hyundai i20 Sportz Diesel  Diesel  ...      90 bhp  22.4 kgm at 1750-2750rpm
#&gt; 4        Maruti Swift VXI BSIII  Petrol  ...    88.2 bhp     11.5@ 4,500(kgm@ rpm)
#&gt; 
#&gt; [5 rows x 9 columns]</code></pre>
<p>Pada data kategorikal, dapat dilihat bahwa beberapa kolom merupakan data yang dapat dijadikan numerik karena mengandung angka di dalamnya, yaitu data pada kolom <code>mileage</code>, <code>engine</code>, <code>max_power</code>, dan <code>torque</code>. Maka perlu dilakukan ekstraksi dengan bantuan <em>regular expression</em> untuk mengambil angka saja. Angka yang telah di ekstrak akan di format menjadi <em>float</em> atau <em>integer</em> dan dijadikan kolom baru pada dataframe numerik <code>df_num</code>.</p>
<pre class="python"><code>df_num[&#39;mileage_kmpl&#39;] = df_cat[&#39;mileage&#39;].str.extract(r&#39;([0-9.,]+)&#39;).astype(&#39;float&#39;)
df_num[&#39;engine_CC&#39;] = df_cat[&#39;engine&#39;].str.extract(r&#39;([0-9.,]+)&#39;).astype(&#39;float&#39;)
df_num[&#39;max_power_bhp&#39;] = df_cat[&#39;max_power&#39;].str.extract(r&#39;([0-9.,]+)&#39;).astype(&#39;float&#39;)</code></pre>
<p>Untuk kolom <code>torque</code>, dipisahkan menjadi 3 bagian, yaitu nilai <strong>Nm</strong>, <strong>rpm minimum</strong>, dan <strong>rpm maksimum</strong>. Apabila angka <strong>rpm</strong> hanya satu, <strong>rpm maksimum</strong> diasumsikan sama dengan <strong>rpm minimum</strong>.</p>
<pre class="python"><code>df_cat[&#39;torque&#39;]</code></pre>
<pre><code>#&gt; 0                  190Nm@ 2000rpm
#&gt; 1             250Nm@ 1500-2500rpm
#&gt; 2           12.7@ 2,700(kgm@ rpm)
#&gt; 3        22.4 kgm at 1750-2750rpm
#&gt; 4           11.5@ 4,500(kgm@ rpm)
#&gt;                   ...            
#&gt; 8123             113.7Nm@ 4000rpm
#&gt; 8124    24@ 1,900-2,750(kgm@ rpm)
#&gt; 8125               190Nm@ 2000rpm
#&gt; 8126          140Nm@ 1800-3000rpm
#&gt; 8127          140Nm@ 1800-3000rpm
#&gt; Name: torque, Length: 7906, dtype: object</code></pre>
<pre class="python"><code>df_cat[&#39;torque&#39;].str.extract(r&#39;([.,0-9]+).*&#39;).head()</code></pre>
<pre><code>#&gt;       0
#&gt; 0   190
#&gt; 1   250
#&gt; 2  12.7
#&gt; 3  22.4
#&gt; 4  11.5</code></pre>
<pre class="python"><code>df_cat[&#39;torque&#39;].str.extract(r&#39;[0-9.,].+?[a-zA-Z@].+?([0-9.,]+)&#39;).replace(&#39;,&#39;,&#39;&#39;, regex=True).head()</code></pre>
<pre><code>#&gt;       0
#&gt; 0  2000
#&gt; 1  1500
#&gt; 2  2700
#&gt; 3  1750
#&gt; 4  4500</code></pre>
<pre class="python"><code>df_cat[&#39;torque&#39;].str.extract(r&#39;([\d,.]+)(?!.*\d)&#39;).replace(&#39;,&#39;,&#39;&#39;, regex=True).head()</code></pre>
<pre><code>#&gt;       0
#&gt; 0  2000
#&gt; 1  2500
#&gt; 2  2700
#&gt; 3  2750
#&gt; 4  4500</code></pre>
<pre class="python"><code>df_num[&#39;torque_Nm&#39;] = df_cat[&#39;torque&#39;].str.extract(r&#39;([.,0-9]+).*&#39;).astype(&#39;float&#39;)
df_num[&#39;torque_rpm_min&#39;] = df_cat[&#39;torque&#39;].str.extract(r&#39;[0-9.,].+?[a-zA-Z@].+?([0-9.,]+)&#39;).replace(&#39;,&#39;,&#39;&#39;, regex=True).astype(&#39;float&#39;)
df_num[&#39;torque_rpm_max&#39;] = df_cat[&#39;torque&#39;].str.extract(r&#39;([\d,.]+)(?!.*\d)&#39;).replace(&#39;,&#39;,&#39;&#39;, regex=True).astype(&#39;float&#39;)</code></pre>
<pre class="python"><code>df_num.head()</code></pre>
<pre><code>#&gt;    year  selling_price  km_driven  ...  torque_Nm  torque_rpm_min  torque_rpm_max
#&gt; 0  2014         450000     145500  ...      190.0          2000.0          2000.0
#&gt; 1  2014         370000     120000  ...      250.0          1500.0          2500.0
#&gt; 2  2006         158000     140000  ...       12.7          2700.0          2700.0
#&gt; 3  2010         225000     127000  ...       22.4          1750.0          2750.0
#&gt; 4  2007         130000     120000  ...       11.5          4500.0          4500.0
#&gt; 
#&gt; [5 rows x 10 columns]</code></pre>
<p>Hapus kolom <code>mileage</code>, <code>engine</code>, <code>max power</code>, dan <code>torque</code> pada dataframe kategori karena kolom-kolom tersebut sudah menjadi bagian dari data numerikal.</p>
<pre class="python"><code>df_cat.drop(columns = [&#39;mileage&#39;, &#39;engine&#39;, &#39;max_power&#39;, &#39;torque&#39;], axis = 1, inplace = True)</code></pre>
<pre class="python"><code>df_cat.head()</code></pre>
<pre><code>#&gt;                            name    fuel seller_type transmission         owner
#&gt; 0        Maruti Swift Dzire VDI  Diesel  Individual       Manual   First Owner
#&gt; 1  Skoda Rapid 1.5 TDI Ambition  Diesel  Individual       Manual  Second Owner
#&gt; 2      Honda City 2017-2020 EXi  Petrol  Individual       Manual   Third Owner
#&gt; 3     Hyundai i20 Sportz Diesel  Diesel  Individual       Manual   First Owner
#&gt; 4        Maruti Swift VXI BSIII  Petrol  Individual       Manual   First Owner</code></pre>
</div>
<div id="eda-and-feature-selection" class="section level2">
<h2>EDA and Feature Selection</h2>
<p>Untuk menentukan fitur-fitur yang diperlukan pada data numerik, perlu dilihat korelasi fitur-fitur tersebut terhadap variabel <code>selling_price</code> selaku <em>target value</em> yang akan diprediksi.</p>
<pre class="python"><code>plt.figure(figsize = (15,15))</code></pre>

<pre class="python"><code>sns.heatmap(df_num.corr(), annot = True)</code></pre>
<pre><code>#&gt; &lt;AxesSubplot:&gt;</code></pre>
<pre class="python"><code>plt.show()</code></pre>
<p><img src="/blog/2021-05-22-gridsearchcv_files/figure-html/unnamed-chunk-1-3.png" width="1440" style="display: block; margin: auto;" /></p>
<pre class="python"><code>plt.figure()</code></pre>

<pre class="python"><code>sns.pairplot(df_num)</code></pre>
<p><img src="/blog/2021-05-22-gridsearchcv_files/figure-html/unnamed-chunk-22-5.png" width="1228" style="display: block; margin: auto;" /></p>
<p>Pilih fitur-fitur yang memiliki korelasi tertinggi terhadap <code>selling_price</code>, pada kasus ini diambil fitur yang memiliki korelasi di atas 0.4. Fitur numerik dengan korelasi tertinggi dimuat di dalam variabel <code>highest_corr_features</code>.</p>
<pre class="python"><code>plt.figure(figsize = (15,15))</code></pre>

<pre class="python"><code>corr = df_num.corr()

# Ambil fitur dengan korelasi dengan selling_price di atas 0.4
highest_corr_features = corr.index[abs(corr[&quot;selling_price&quot;])&gt;0.4]

plt.figure(figsize=(10,10))</code></pre>

<pre class="python"><code>g = sns.heatmap(df_num[highest_corr_features].corr(),annot=True,cmap=&quot;RdYlGn&quot;)
plt.show()</code></pre>
<p><img src="/blog/2021-05-22-gridsearchcv_files/figure-html/unnamed-chunk-1-7.png" width="960" style="display: block; margin: auto;" /></p>
<p>Untuk fitur data kategorikal, perlu dilihat terlebih dahulu berapa banyak <em>unique value</em> dari fitur tersebut.</p>
<pre class="python"><code>df_cat.nunique()</code></pre>
<pre><code>#&gt; name            1982
#&gt; fuel               4
#&gt; seller_type        3
#&gt; transmission       2
#&gt; owner              5
#&gt; dtype: int64</code></pre>
<p>Karena kolom <code>name</code> <em>unique value</em> nya sangat banyak, kolom <code>name</code> sebaiknya di drop karena sangat sedikit berpengaruh terhadap performa model. Selanjutnya akan dilakukan <em>One-Hot Encoding</em> (mengubah setiap kategori menjadi kolom) yang berisi nilai antara 0 atau 1.</p>
<pre class="python"><code># drop kolom name
df_cat.drop(columns = [&#39;name&#39;], axis = 1, inplace = True)</code></pre>
<pre class="python"><code># Lakukan One-Hot Encoding
df_cat = pd.get_dummies(df_cat)</code></pre>
<pre class="python"><code>df_cat.head(3)</code></pre>
<pre><code>#&gt;    fuel_CNG  fuel_Diesel  ...  owner_Test Drive Car  owner_Third Owner
#&gt; 0         0            1  ...                     0                  0
#&gt; 1         0            1  ...                     0                  0
#&gt; 2         0            0  ...                     0                  1
#&gt; 
#&gt; [3 rows x 14 columns]</code></pre>
<p>Selanjutnya akan dilakukan pemilihan fitur kategorikal. Fitur kategorikal dipilih berdasarkan nilai <em>chi-squared</em> terbesar. Semakin tinggi nilai <em>chi squared</em> maka semakin signifikan pengaruh fitur tersebut terhadap <em>target value</em>. Fitur kategorikal terbaik dimuat di dalam valiabel <code>top_cat</code> yang memuat 5 fitur terpenting.</p>
<pre class="python"><code># Selanjutnya memilih fitur kategorikal yang penting berdasarkan nilai chi2
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2</code></pre>
<pre class="python"><code># Applying kbest algo
ordered_rank_features = SelectKBest(score_func=chi2, k=14)
ordered_feature = ordered_rank_features.fit(df_cat,df_num[&#39;selling_price&#39;])
ordered_feature.scores_</code></pre>
<pre><code>#&gt; array([ 926.72869219,  887.69415145, 1149.59778626, 1047.29106073,
#&gt;        2733.56058706,  527.54944917, 2908.88674579, 3618.03100769,
#&gt;         548.63368959,  663.81035178,  930.07841487,  917.43378246,
#&gt;        4886.68063492,  978.79804926])</code></pre>
<pre class="python"><code>df_scores = pd.DataFrame(ordered_feature.scores_, columns=[&#39;Score&#39;])
df_columns = pd.DataFrame(df_cat.columns)
univariate_ranked = pd.concat([df_columns, df_scores],axis=1)
univariate_ranked.columns = [&#39;Features&#39;, &#39;Scores&#39;]
univariate_ranked.set_index(&#39;Features&#39;, inplace = True)

# Ambil 5 fitur paling penting
top_cat = univariate_ranked.sort_values(&#39;Scores&#39;, ascending = False).head()
top_cat</code></pre>
<pre><code>#&gt;                                    Scores
#&gt; Features                                 
#&gt; owner_Test Drive Car          4886.680635
#&gt; transmission_Automatic        3618.031008
#&gt; seller_type_Trustmark Dealer  2908.886746
#&gt; seller_type_Dealer            2733.560587
#&gt; fuel_LPG                      1149.597786</code></pre>
<p>Data kategorikal dan data numerikal disatukan kembali menjadi dataframe baru dengan nama <code>df_new</code>.</p>
<pre class="python"><code>df_new = pd.concat([df_num, df_cat], axis = 1)</code></pre>
<pre class="python"><code>df_new.head()</code></pre>
<pre><code>#&gt;    year  selling_price  ...  owner_Test Drive Car  owner_Third Owner
#&gt; 0  2014         450000  ...                     0                  0
#&gt; 1  2014         370000  ...                     0                  0
#&gt; 2  2006         158000  ...                     0                  1
#&gt; 3  2010         225000  ...                     0                  0
#&gt; 4  2007         130000  ...                     0                  0
#&gt; 
#&gt; [5 rows x 24 columns]</code></pre>
<pre class="python"><code># cek kembali data yang hilang
df_new.isnull().sum()</code></pre>
<pre><code>#&gt; year                             0
#&gt; selling_price                    0
#&gt; km_driven                        0
#&gt; seats                            0
#&gt; mileage_kmpl                     0
#&gt; engine_CC                        0
#&gt; max_power_bhp                    0
#&gt; torque_Nm                        0
#&gt; torque_rpm_min                  42
#&gt; torque_rpm_max                   0
#&gt; fuel_CNG                         0
#&gt; fuel_Diesel                      0
#&gt; fuel_LPG                         0
#&gt; fuel_Petrol                      0
#&gt; seller_type_Dealer               0
#&gt; seller_type_Individual           0
#&gt; seller_type_Trustmark Dealer     0
#&gt; transmission_Automatic           0
#&gt; transmission_Manual              0
#&gt; owner_First Owner                0
#&gt; owner_Fourth &amp; Above Owner       0
#&gt; owner_Second Owner               0
#&gt; owner_Test Drive Car             0
#&gt; owner_Third Owner                0
#&gt; dtype: int64</code></pre>
<pre class="python"><code># drop missing values
df_new.dropna(inplace = True)</code></pre>
<pre class="python"><code>df_new.head()</code></pre>
<pre><code>#&gt;    year  selling_price  ...  owner_Test Drive Car  owner_Third Owner
#&gt; 0  2014         450000  ...                     0                  0
#&gt; 1  2014         370000  ...                     0                  0
#&gt; 2  2006         158000  ...                     0                  1
#&gt; 3  2010         225000  ...                     0                  0
#&gt; 4  2007         130000  ...                     0                  0
#&gt; 
#&gt; [5 rows x 24 columns]</code></pre>
</div>
<div id="data-preprocessing" class="section level2">
<h2>Data Preprocessing</h2>
<p>Pada tahap ini akan dilakukan <em>preprocessing</em> yaitu pemrosesan data awal yang bertujuan untuk mempersiapkan data agar dapat diterima oleh model <em>machine learning</em> dengan baik. Pada tahapan ini meliputi penentuan <em>target value</em> <code>y</code>, penentuan prediktor <code>X</code>, normalisasi data, dan <em>train test split</em>.</p>
<pre class="python"><code># Tentukan target value (y)
y = df_new[&#39;selling_price&#39;]</code></pre>
<pre class="python"><code># Menentukan predictor
# Fitur yang diambil untuk menjadi predictor adalah fitur yang telah melalui proses seleksi
# Highest corr features adalah fitur numerik dengan korelasi terhadap price yang tinggi
highest_corr_features.tolist()</code></pre>
<pre><code>#&gt; [&#39;year&#39;, &#39;selling_price&#39;, &#39;engine_CC&#39;, &#39;max_power_bhp&#39;, &#39;torque_Nm&#39;]</code></pre>
<pre class="python"><code># top_cat adalah fitur kategori dengan nilai chi2 terhadap price yang tertinggi
top_cat.index.tolist()</code></pre>
<pre><code>#&gt; [&#39;owner_Test Drive Car&#39;, &#39;transmission_Automatic&#39;, &#39;seller_type_Trustmark Dealer&#39;, &#39;seller_type_Dealer&#39;, &#39;fuel_LPG&#39;]</code></pre>
<pre class="python"><code># Tentukan predictor (X) dengan melakukan subsetting dataframe
X = df_new[top_cat.index.tolist()+highest_corr_features.tolist()]</code></pre>
<p>Setelah ditentukan <em>target value</em> dan <em>predictor</em>, dilanjutkan dengan normalisasi data menggunakan <em>MinMaxScaler</em> dan pembagian data train dan data test atau biasa dikenal dengan istilah <em>train test split</em>.</p>
<pre class="python"><code>from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error</code></pre>
<pre class="python"><code># Normalisasi data
sc = MinMaxScaler()
X = sc.fit_transform(X)</code></pre>
<pre class="python"><code># Train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
X_train.shape, X_test.shape, y_train.shape, y_test.shape</code></pre>
<pre><code>#&gt; ((6291, 10), (1573, 10), (6291,), (1573,))</code></pre>
</div>
<div id="model-selection-with-gridsearchcv" class="section level2">
<h2>Model Selection with GridSearchCV</h2>
<p><em>GridSearchCV</em> merupakan bagian dari modul <em>scikit-learn</em> yang bertujuan untuk melakukan validasi untuk lebih dari satu model dan hyperparameter masing-masing secara otomatis dan sistematis. Sebagai contoh, kita ingin mencoba model <em>Decision Tree</em> <em>hyperparameter</em> <code>min_samples_leaf</code> dengan nilai 1, 2, dan 3 dan <code>min_samples_split</code> dengan nilai 2,3, dan 4. <em>GridSearchCV</em> akan memilih <em>hyperparameter</em> mana yang akan memberikan model performa yang terbaik. Pada kasus ini, nilai <code>cv</code> diset 5 yang menandakan setiap kombinasi model dan parameter divalidasi sebanyak 5 kali dengan membagi data sebanyak 5 bagian sama besar secara acak (4 bagian untuk training dan 1 bagian untuk testing).</p>
<pre class="python"><code>from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeRegressor

model = DecisionTreeRegressor()

parameters = {
        &#39;min_samples_leaf&#39;: [1, 2, 3],
        &#39;min_samples_split&#39;: [2, 3, 4]
        }</code></pre>
<pre class="python"><code>search = GridSearchCV(model,
                        parameters,
                        cv = 5,
                        
                        verbose=3)
search.fit(X, y)</code></pre>
<pre><code>#&gt; Fitting 5 folds for each of 9 candidates, totalling 45 fits
#&gt; [CV 1/5] END min_samples_leaf=1, min_samples_split=2;, score=0.993 total time=   0.0s
#&gt; [CV 2/5] END min_samples_leaf=1, min_samples_split=2;, score=0.999 total time=   0.0s
#&gt; [CV 3/5] END min_samples_leaf=1, min_samples_split=2;, score=1.000 total time=   0.0s
#&gt; [CV 4/5] END min_samples_leaf=1, min_samples_split=2;, score=1.000 total time=   0.0s
#&gt; [CV 5/5] END min_samples_leaf=1, min_samples_split=2;, score=1.000 total time=   0.0s
#&gt; [CV 1/5] END min_samples_leaf=1, min_samples_split=3;, score=0.992 total time=   0.0s
#&gt; [CV 2/5] END min_samples_leaf=1, min_samples_split=3;, score=0.999 total time=   0.0s
#&gt; [CV 3/5] END min_samples_leaf=1, min_samples_split=3;, score=1.000 total time=   0.0s
#&gt; [CV 4/5] END min_samples_leaf=1, min_samples_split=3;, score=1.000 total time=   0.0s
#&gt; [CV 5/5] END min_samples_leaf=1, min_samples_split=3;, score=1.000 total time=   0.0s
#&gt; [CV 1/5] END min_samples_leaf=1, min_samples_split=4;, score=0.992 total time=   0.0s
#&gt; [CV 2/5] END min_samples_leaf=1, min_samples_split=4;, score=0.999 total time=   0.0s
#&gt; [CV 3/5] END min_samples_leaf=1, min_samples_split=4;, score=1.000 total time=   0.0s
#&gt; [CV 4/5] END min_samples_leaf=1, min_samples_split=4;, score=1.000 total time=   0.0s
#&gt; [CV 5/5] END min_samples_leaf=1, min_samples_split=4;, score=1.000 total time=   0.0s
#&gt; [CV 1/5] END min_samples_leaf=2, min_samples_split=2;, score=0.992 total time=   0.0s
#&gt; [CV 2/5] END min_samples_leaf=2, min_samples_split=2;, score=0.999 total time=   0.0s
#&gt; [CV 3/5] END min_samples_leaf=2, min_samples_split=2;, score=1.000 total time=   0.0s
#&gt; [CV 4/5] END min_samples_leaf=2, min_samples_split=2;, score=0.999 total time=   0.0s
#&gt; [CV 5/5] END min_samples_leaf=2, min_samples_split=2;, score=1.000 total time=   0.0s
#&gt; [CV 1/5] END min_samples_leaf=2, min_samples_split=3;, score=0.992 total time=   0.0s
#&gt; [CV 2/5] END min_samples_leaf=2, min_samples_split=3;, score=0.999 total time=   0.0s
#&gt; [CV 3/5] END min_samples_leaf=2, min_samples_split=3;, score=1.000 total time=   0.0s
#&gt; [CV 4/5] END min_samples_leaf=2, min_samples_split=3;, score=0.999 total time=   0.0s
#&gt; [CV 5/5] END min_samples_leaf=2, min_samples_split=3;, score=1.000 total time=   0.0s
#&gt; [CV 1/5] END min_samples_leaf=2, min_samples_split=4;, score=0.992 total time=   0.0s
#&gt; [CV 2/5] END min_samples_leaf=2, min_samples_split=4;, score=0.999 total time=   0.0s
#&gt; [CV 3/5] END min_samples_leaf=2, min_samples_split=4;, score=1.000 total time=   0.0s
#&gt; [CV 4/5] END min_samples_leaf=2, min_samples_split=4;, score=0.999 total time=   0.0s
#&gt; [CV 5/5] END min_samples_leaf=2, min_samples_split=4;, score=1.000 total time=   0.0s
#&gt; [CV 1/5] END min_samples_leaf=3, min_samples_split=2;, score=0.990 total time=   0.0s
#&gt; [CV 2/5] END min_samples_leaf=3, min_samples_split=2;, score=1.000 total time=   0.0s
#&gt; [CV 3/5] END min_samples_leaf=3, min_samples_split=2;, score=1.000 total time=   0.0s
#&gt; [CV 4/5] END min_samples_leaf=3, min_samples_split=2;, score=0.999 total time=   0.0s
#&gt; [CV 5/5] END min_samples_leaf=3, min_samples_split=2;, score=1.000 total time=   0.0s
#&gt; [CV 1/5] END min_samples_leaf=3, min_samples_split=3;, score=0.990 total time=   0.0s
#&gt; [CV 2/5] END min_samples_leaf=3, min_samples_split=3;, score=1.000 total time=   0.0s
#&gt; [CV 3/5] END min_samples_leaf=3, min_samples_split=3;, score=1.000 total time=   0.0s
#&gt; [CV 4/5] END min_samples_leaf=3, min_samples_split=3;, score=0.999 total time=   0.0s
#&gt; [CV 5/5] END min_samples_leaf=3, min_samples_split=3;, score=1.000 total time=   0.0s
#&gt; [CV 1/5] END min_samples_leaf=3, min_samples_split=4;, score=0.990 total time=   0.0s
#&gt; [CV 2/5] END min_samples_leaf=3, min_samples_split=4;, score=1.000 total time=   0.0s
#&gt; [CV 3/5] END min_samples_leaf=3, min_samples_split=4;, score=1.000 total time=   0.0s
#&gt; [CV 4/5] END min_samples_leaf=3, min_samples_split=4;, score=0.999 total time=   0.0s
#&gt; [CV 5/5] END min_samples_leaf=3, min_samples_split=4;, score=1.000 total time=   0.0s
#&gt; GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),
#&gt;              param_grid={&#39;min_samples_leaf&#39;: [1, 2, 3],
#&gt;                          &#39;min_samples_split&#39;: [2, 3, 4]},
#&gt;              verbose=3)</code></pre>
<p>Setelah dilakukan <em>Grid Search</em>, skor dan parameter terbaik dapat ditentukan seperti berikut ini.</p>
<pre class="python"><code>search.best_score_, search.best_params_</code></pre>
<pre><code>#&gt; (0.9984489525832239, {&#39;min_samples_leaf&#39;: 1, &#39;min_samples_split&#39;: 2})</code></pre>
<p>Parameter tersebut dapat langsung digunakan untuk melakukan prediksi terhadap <code>selling_price</code>.</p>
<pre class="python"><code>model = DecisionTreeRegressor(min_samples_leaf = search.best_params_[&#39;min_samples_leaf&#39;], 
                              min_samples_split = search.best_params_[&#39;min_samples_split&#39;])
model.fit(X_train, y_train)</code></pre>
<pre><code>#&gt; DecisionTreeRegressor()</code></pre>
<pre class="python"><code>y_pred = model.predict(X_test)

print(&#39;r-squared is &#39;, r2_score(y_test, y_pred),&#39; and root_mean_squared_error is &#39;,  mean_squared_error(y_test, y_pred, squared = False))</code></pre>
<pre><code>#&gt; r-squared is  0.9998793137480012  and root_mean_squared_error is  8295.357724466106</code></pre>
<pre class="python"><code>def plot_result(prediction, actual):
  plt.figure(figsize = (7,7))
  plt.scatter(prediction, actual, color = &#39;r&#39;, s = 5)
  plt.xlabel(&#39;Prediction&#39;)
  plt.ylabel(&#39;Actual&#39;)
  plt.plot([0,3e6], [0,3e6])
  plt.show()
  
plot_result(y_pred, y_test)</code></pre>
<p><img src="/blog/2021-05-22-gridsearchcv_files/figure-html/unnamed-chunk-1-9.png" width="672" style="display: block; margin: auto;" /></p>
<p>Apabila ingin mencoba lebih dari satu buah model, grid search dilakukan dengan melakukan iterasi untuk setiap model. Karena setiap model memiliki input parameter yang berbeda-beda, iterasi harus berjalan untuk setiap model sesuai dengan parameternya masing-masing. Untuk menangani hal tersebut, perlu dirancang kumpulan <em>dictionary</em> sebagai berikut ini. Asumsikan kita ingin mencoba mode <em>Linear Regression</em>, <em>Decision Tree Regressor</em>, dan <em>Random Forest Regressor</em> dengan masing-masing parameter seperti tertera di bawah ini.</p>
<pre class="python"><code>from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor

model_params = {
    &#39;linear_regression&#39;: {
        &#39;model&#39;: LinearRegression(),
        &#39;params&#39; : {
            # No Parameter
        }  
    },
    &#39;decision_tree&#39;: {
        &#39;model&#39;: DecisionTreeRegressor(),
        &#39;params&#39; : {
            &#39;min_samples_leaf&#39; : [1,2,3]
        }
    },
    &#39;random_forest&#39;: {
        &#39;model&#39;: RandomForestRegressor(),
        &#39;params&#39; : {
            &#39;n_estimators&#39;: [100, 500],
            &#39;min_samples_leaf&#39; : [1,2,3]
        }
    },    

}</code></pre>
<p>GridSearchCV dilakukan dengan iterasi untuk setiap model. Skor dan parameter terbaik disimpan di dalam list <code>scores</code> yang nantinya akan dimuat dalam bentuk dataframe.</p>
<pre class="python"><code>scores = []

for model_name, mp in model_params.items():
    clf =  GridSearchCV(mp[&#39;model&#39;], mp[&#39;params&#39;], cv=5, return_train_score=False)
    clf.fit(X, y)
    scores.append({
        &#39;model&#39;: model_name,
        &#39;best_score&#39;: clf.best_score_,
        &#39;best_params&#39;: clf.best_params_
    })
    </code></pre>
<pre><code>#&gt; GridSearchCV(cv=5, estimator=LinearRegression(), param_grid={})
#&gt; GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),
#&gt;              param_grid={&#39;min_samples_leaf&#39;: [1, 2, 3]})
#&gt; GridSearchCV(cv=5, estimator=RandomForestRegressor(),
#&gt;              param_grid={&#39;min_samples_leaf&#39;: [1, 2, 3],
#&gt;                          &#39;n_estimators&#39;: [100, 500]})</code></pre>
<pre class="python"><code>score_df = pd.DataFrame(scores,columns=[&#39;model&#39;,&#39;best_score&#39;,&#39;best_params&#39;])
score_df</code></pre>
<pre><code>#&gt;                model  best_score                                   best_params
#&gt; 0  linear_regression    1.000000                                            {}
#&gt; 1      decision_tree    0.997913                       {&#39;min_samples_leaf&#39;: 2}
#&gt; 2      random_forest    0.997849  {&#39;min_samples_leaf&#39;: 1, &#39;n_estimators&#39;: 500}</code></pre>
<p>Dapat dilihat bahwa model <em>Simple Linear Regression</em> memiliki <em>r-squared</em> <em>score</em> tertinggi. Sehingga model ini dapat langsung digunakan untuk memprediksi <em>target value</em>.</p>
<pre class="python"><code>model = LinearRegression()
model.fit(X_train, y_train)</code></pre>
<pre><code>#&gt; LinearRegression()</code></pre>
<pre class="python"><code>y_pred = model.predict(X_test)
print(&#39;r-squared is &#39;, r2_score(y_test, y_pred),&#39; and root_mean_squared_error is &#39;,  mean_squared_error(y_test, y_pred, squared = False))</code></pre>
<pre><code>#&gt; r-squared is  1.0  and root_mean_squared_error is  1.3150676180075858e-09</code></pre>
<pre class="python"><code>plot_result(y_pred, y_test)</code></pre>
<p><img src="/blog/2021-05-22-gridsearchcv_files/figure-html/unnamed-chunk-1-11.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>Penentuan hasil prediksi dari suatu data dititikberatkan pada pemilihan model dan parameter yang baik. <em>Grid Search Cross Validation</em> mempermudah kita dalam menguji coba setiap model dan parameter model <em>machine learning</em> tanpa harus mencoba melakukan validasi secara manual satu persatu. Penerapan <em>Grid Search Cross Validation</em> yang disandingkan dengan pemahaman dan intuisi yang baik terkait model <em>machine learning</em> dan data yang digunakan akan memberikan hasil prediksi yang akurat dan optimal.</p>
<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html">Dokumentasi GridSearchCV library sklearn</a></p>
<p><a href="https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho">Data Vehicle Kaggle</a></p>
<p><a href="https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/">Cross Validation and Grid Search for Model Selection in Python</a></p>
</div>
